{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model exposed through API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\agadiya\\\\Desktop\\\\Convergence - Launch your Ideas\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=pd.read_csv(\"response.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health_app_code</th>\n",
       "      <th>ques_1_response</th>\n",
       "      <th>ques_2_response</th>\n",
       "      <th>ques_3_response</th>\n",
       "      <th>ques_4_response</th>\n",
       "      <th>ques_5_response</th>\n",
       "      <th>ques_6_response</th>\n",
       "      <th>ques_7_response</th>\n",
       "      <th>ques_8_response</th>\n",
       "      <th>ques_9_response</th>\n",
       "      <th>ques_10_response</th>\n",
       "      <th>device_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   health_app_code  ques_1_response  ques_2_response  ques_3_response  \\\n",
       "0                1                0                0                0   \n",
       "1                2                0                0                0   \n",
       "2                3                1                0                1   \n",
       "3                4                0                1                0   \n",
       "4                5                1                0                1   \n",
       "\n",
       "   ques_4_response  ques_5_response  ques_6_response  ques_7_response  \\\n",
       "0                0                0                0                1   \n",
       "1                0                0                1                0   \n",
       "2                1                0                1                1   \n",
       "3                0                1                1                1   \n",
       "4                1                0                1                0   \n",
       "\n",
       "   ques_8_response  ques_9_response  ques_10_response  device_class  \n",
       "0                0                0                 1             2  \n",
       "1                1                0                 0             3  \n",
       "2                1                0                 0             1  \n",
       "3                1                1                 0             3  \n",
       "4                1                1                 1             3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = response.iloc[:, 1:11].values\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = response.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, ..., 1, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agadiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agadiya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3541666666666667\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 2 1 3 1 1 1 1 1 2 3 2 1 3 2 1 2 2 2 3 3 2 3 1 1 1 2 2 2 3 2 1 2 2 3\n",
      " 3 3 1 3 3 3 1 3 3 3 2 3 1 2 3 1 3 1 3 1 1 2 2 2 3 3 3 3 2 3 1 2 1 3 3 3 1\n",
      " 2 2 2 1 2 2 2 3 3 2 2 1 3 1 1 2 1 3 3 3 3 1 1 1 2 3 3 3 2 1 1 1 3 1 1 3 2\n",
      " 3 2 1 2 1 2 1 1 2 3 3 1 3 1 1 2 2 2 1 1 1 2 1 2 2 1 2 1 3 2 2 1 1 2 3 2 2\n",
      " 2 1 1 1 2 2 1 1 3 1 2 3 2 1 2 1 3 3 3 2 2 3 3 3 2 2 2 2 3 2 3 1 1 3 1 3 2\n",
      " 2 2 3 2 3 1 3 2 2 2 3 1 1 2 2 1 1 2 1 1 3 2 2 1 1 1 3 2 3 1 3 1 1 1 1 3 3\n",
      " 1 2 1 1 2 2 3 2 2 1 1 2 2 2 3 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "pred = loaded_model.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1=loaded_model.predict([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [06/Dec/2018 13:59:47] \"OPTIONS /api/make_predict?ques_1_response=0&ques_2_response=1&ques_3_response=1&ques_4_response=0&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 14:01:43] \"OPTIONS /api/make_predict?ques_1_response=1&ques_2_response=1&ques_3_response=1&ques_4_response=1&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 14:01:44] \"POST /api/make_predict?ques_1_response=1&ques_2_response=1&ques_3_response=1&ques_4_response=1&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 14:13:23] \"OPTIONS /api/make_predict?ques_1_response=1&ques_2_response=0&ques_3_response=0&ques_4_response=1&ques_5_response=1&ques_6_response=0&ques_7_response=0&ques_8_response=1&ques_9_response=0&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 14:13:24] \"POST /api/make_predict?ques_1_response=1&ques_2_response=0&ques_3_response=0&ques_4_response=1&ques_5_response=1&ques_6_response=0&ques_7_response=0&ques_8_response=1&ques_9_response=0&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 14:25:09] \"OPTIONS /api/make_predict?ques_1_response=0&ques_2_response=1&ques_3_response=1&ques_4_response=0&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 14:25:09] \"POST /api/make_predict?ques_1_response=0&ques_2_response=1&ques_3_response=1&ques_4_response=0&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 15:23:56] \"POST /api/make_predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 15:39:08] \"OPTIONS /api/make_predict?ques_1_response=1&ques_2_response=0&ques_3_response=1&ques_4_response=0&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 15:39:08] \"POST /api/make_predict?ques_1_response=1&ques_2_response=0&ques_3_response=1&ques_4_response=0&ques_5_response=1&ques_6_response=0&ques_7_response=1&ques_8_response=0&ques_9_response=1&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 21:56:37] \"OPTIONS /api/make_predict?ques_1_response=0&ques_2_response=1&ques_3_response=1&ques_4_response=0&ques_5_response=0&ques_6_response=1&ques_7_response=1&ques_8_response=0&ques_9_response=0&ques_10_response=0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Dec/2018 21:56:37] \"POST /api/make_predict?ques_1_response=0&ques_2_response=1&ques_3_response=1&ques_4_response=0&ques_5_response=0&ques_6_response=1&ques_7_response=1&ques_8_response=0&ques_9_response=0&ques_10_response=0 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, abort, jsonify, request\n",
    "import pickle\n",
    "from flask import Response\n",
    "\n",
    "\n",
    "my_random_forest = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "app= Flask(__name__)\n",
    "\n",
    "@app.route('/api/make_predict',methods=['POST'])\n",
    "\n",
    "def make_predict():\n",
    "    #all kinds of error checking should go here\n",
    "    data = request.get_json(force=True)\n",
    "    #convert our json to numpy array\n",
    "    predict_request = [data['ques_1_response'],data['ques_2_response'],data['ques_3_response'],data['ques_4_response'],data['ques_5_response'],data['ques_6_response'],data['ques_7_response'],data['ques_8_response'],data['ques_9_response'],data['ques_10_response']]\n",
    "    #predict_request1=np.array(predict_request)\n",
    "    predict_request1 = [predict_request]\n",
    "    #np array goes into random forest\n",
    "    y_hat=my_random_forest.predict(predict_request1)\n",
    "    #return our prediction\n",
    "    output=[y_hat[0]]\n",
    "    prediction_series = list(pd.Series(y_hat[0]))\n",
    "    final_predictions = pd.DataFrame(list(prediction_series))\n",
    "    responses = jsonify(predictions=final_predictions.to_json(orient=\"records\"))\n",
    "   # responses.status_code = 200\n",
    "    return (responses)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
